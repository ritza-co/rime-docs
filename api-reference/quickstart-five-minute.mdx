---
title: Generate text-to-speech in five minutes
icon: rocket
---

This guide shows you how to generate your first audio clip with Rime's text-to-speech (TTS) API and experiment with different voices and speech customizations.

## Prerequisites

To follow this guide, you need:

- **A Rime API token:** Create a free [Rime account](https://app.rime.ai/signup/) and copy your API key from the [API Tokens](https://app.rime.ai/tokens/) page.
- A language runtime:
  - **[Python 3.10](https://www.python.org/downloads/release/python-3100/) or later**, or
  - **[Node.js 18](https://nodejs.org/) or later** (JavaScript or TypeScript)

Code blocks in this guide are tabbed. Pick Python, JavaScript, or TypeScript in each block to follow your preferred language.

## Create your script

If you'd rather paste a working file and read along, grab the full script below. Otherwise, continue step-by-step.

### Full script

Create a file called `rime_hello_world.py`, `rime_hello_world.js`, or `rime_hello_world.ts` and paste the full script:

<Accordion title="Full script (copy/paste)">
<CodeGroup>
```python Python
import json
import urllib.request

RIME_API_KEY = "your_api_key_here"

headers = {
    "Accept": "audio/mp3",
    "Authorization": f"Bearer {RIME_API_KEY}",
    "Content-Type": "application/json"
}

payload = {
    "text": "Hello! This is Rime speaking.",
    "speaker": "celeste",
    "modelId": "arcana"
}

data = json.dumps(payload).encode("utf-8")

request = urllib.request.Request(
    "https://users.rime.ai/v1/rime-tts",
    data=data,
    headers=headers,
    method="POST"
)

with urllib.request.urlopen(request) as response:
    with open("output.mp3", "wb") as f:
        while chunk := response.read(4096):
            f.write(chunk)

print("Audio saved to output.mp3")
```

```javascript JavaScript
const fs = require("fs");

const RIME_API_KEY = "your_api_key_here";

const headers = {
    "Accept": "audio/mp3",
    "Authorization": `Bearer ${RIME_API_KEY}`,
    "Content-Type": "application/json"
};

const payload = {
    text: "Hello! This is Rime speaking.",
    speaker: "celeste",
    modelId: "arcana"
};

async function generateSpeech() {
    const response = await fetch("https://users.rime.ai/v1/rime-tts", {
        method: "POST",
        headers: headers,
        body: JSON.stringify(payload)
    });

    if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
    }

    const buffer = await response.arrayBuffer();
    fs.writeFileSync("output.mp3", Buffer.from(buffer));
    console.log("Audio saved to output.mp3");
}

generateSpeech();
```

```typescript TypeScript
import * as fs from "node:fs";

const RIME_API_KEY = "your_api_key_here";

const headers = {
    "Accept": "audio/mp3",
    "Authorization": `Bearer ${RIME_API_KEY}`,
    "Content-Type": "application/json"
};

const payload = {
    text: "Hello! This is Rime speaking.",
    speaker: "celeste",
    modelId: "arcana"
};

async function generateSpeech() {
    const response = await fetch("https://users.rime.ai/v1/rime-tts", {
        method: "POST",
        headers: headers,
        body: JSON.stringify(payload)
    });

    if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
    }

    const buffer = await response.arrayBuffer();
    fs.writeFileSync("output.mp3", Buffer.from(buffer));
    console.log("Audio saved to output.mp3");
}

generateSpeech();
```
</CodeGroup>
</Accordion>

### Step-by-step code

Create a file called `rime_hello_world.py`, `rime_hello_world.js`, or `rime_hello_world.ts` and import the required library modules:

<CodeGroup>
```python Python
import json
import urllib.request
```

```javascript JavaScript
const fs = require("fs");
```

```typescript TypeScript
import * as fs from "node:fs";
```
</CodeGroup>

Next, we'll create a request to the Rime API.

Set the request headers, specifying the Rime API key that you copied:

<CodeGroup>
```python Python
RIME_API_KEY = "your_api_key_here"

headers = {
    "Accept": "audio/mp3",
    "Authorization": f"Bearer {RIME_API_KEY}",
    "Content-Type": "application/json"
}
```

```javascript JavaScript
const RIME_API_KEY = "your_api_key_here";

const headers = {
    "Accept": "audio/mp3",
    "Authorization": `Bearer ${RIME_API_KEY}`,
    "Content-Type": "application/json"
};
```

```typescript TypeScript
const RIME_API_KEY = "your_api_key_here";

const headers = {
    "Accept": "audio/mp3",
    "Authorization": `Bearer ${RIME_API_KEY}`,
    "Content-Type": "application/json"
};
```
</CodeGroup>

Configure a payload specifying the details of the request:

<CodeGroup>
```python Python
payload = {
    "text": "Hello! This is Rime speaking.",
    "speaker": "celeste",
    "modelId": "arcana"
}
```

```javascript JavaScript
const payload = {
    text: "Hello! This is Rime speaking.",
    speaker: "celeste",
    modelId: "arcana"
};
```

```typescript TypeScript
const payload = {
    text: "Hello! This is Rime speaking.",
    speaker: "celeste",
    modelId: "arcana"
};
```
</CodeGroup>

This payload includes the three required parameters:

- `text` adds the text that the model converts to speech.
- `speaker` sets the voice that the agent uses (view your options on our [Voices](/api-reference/voices) page).
- `modelId` specifies which model the agent uses. Use `arcana` for the most realistic voices, or `mistv2` for faster synthesis.

The [Arcana API reference](/api-reference/arcana/streaming-mp3) details the many optional parameters you can add to request payloads.

Now that you've created the headers and payload, make a `POST` request to the Rime API and write the streamed audio response to a file:

<CodeGroup>
```python Python
data = json.dumps(payload).encode("utf-8")

request = urllib.request.Request(
    "https://users.rime.ai/v1/rime-tts",
    data=data,
    headers=headers,
    method="POST"
)

with urllib.request.urlopen(request) as response:
    with open("output.mp3", "wb") as f:
        while chunk := response.read(4096):
            f.write(chunk)

print("Audio saved to output.mp3")
```

```javascript JavaScript
async function generateSpeech() {
    const response = await fetch("https://users.rime.ai/v1/rime-tts", {
        method: "POST",
        headers: headers,
        body: JSON.stringify(payload)
    });

    if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
    }

    const buffer = await response.arrayBuffer();
    fs.writeFileSync("output.mp3", Buffer.from(buffer));
    console.log("Audio saved to output.mp3");
}

generateSpeech();
```

```typescript TypeScript
async function generateSpeech() {
    const response = await fetch("https://users.rime.ai/v1/rime-tts", {
        method: "POST",
        headers: headers,
        body: JSON.stringify(payload)
    });

    if (!response.ok) {
        throw new Error(`HTTP error! status: ${response.status}`);
    }

    const buffer = await response.arrayBuffer();
    fs.writeFileSync("output.mp3", Buffer.from(buffer));
    console.log("Audio saved to output.mp3");
}

generateSpeech();
```
</CodeGroup>

Streaming allows audio playback to begin before generation completes. This enables conversational flow, as the user can start listening to responses before the entire audio clip has been generated.

Although streaming is less important in this example, because we're writing to a file, it's vital when using models in real-time conversations. If this sounds interesting, follow the [LiveKit quickstart](/api-reference/quickstart-livekit/) to create your first conversational agent.

## Test the script

Run your script from the terminal:

<CodeGroup>
```bash Python
python rime_hello_world.py
```

```bash JavaScript
node rime_hello_world.js
```

```bash TypeScript
npx tsx rime_hello_world.ts
```
</CodeGroup>

On a successful run, the terminal displays a confirmation that your audio file has been saved:

```bash
'Audio saved to output.mp3'
```

<audio controls src="/sounds/example-output.mp3"></audio>

## Choose a voice

Rime offers a range of voices with different personalities. To change the voice, update the `speaker` parameter in your request:

<CodeGroup>
```python Python
payload = {
    "text": "Hello! This is Rime speaking.",
    "speaker": "orion",  # Try different voices here
    "modelId": "arcana"
}
```

```javascript JavaScript
const payload = {
    text: "Hello! This is Rime speaking.",
    speaker: "orion",  // Try different voices here
    modelId: "arcana"
};
```

```typescript TypeScript
const payload = {
    text: "Hello! This is Rime speaking.",
    speaker: "orion",  // Try different voices here
    modelId: "arcana"
};
```
</CodeGroup>

Browse all available voices on the [Voices](/api-reference/voices) page.

## Custom pronunciation

The `mistv2` model lets you specify the pronunciation of brand names or uncommon words using Rime's [phonetic alphabet](/api-reference/custom-pronunciation). Add the custom pronunciation in curly brackets and set `phonemizeBetweenBrackets` to `true`:

<CodeGroup>
```python Python
payload = {
    "text": "Welcome to {r1Ym} labs.",
    "speaker": "peak",
    "modelId": "mistv2",
    "phonemizeBetweenBrackets": True
}
```

```javascript JavaScript
const payload = {
    text: "Welcome to {r1Ym} labs.",
    speaker: "peak",
    modelId: "mistv2",
    phonemizeBetweenBrackets: true
};
```

```typescript TypeScript
const payload = {
    text: "Welcome to {r1Ym} labs.",
    speaker: "peak",
    modelId: "mistv2",
    phonemizeBetweenBrackets: true
};
```
</CodeGroup>

Use the [Pronunciation tool](https://rime.ai/dashboard/pronunciation) on the dashboard to generate phonetic strings for any word.

## Next steps

Now that you can generate TTS audio, try following the [LiveKit quickstart guide](/api-reference/quickstart-livekit) to learn how you can set up a real-time conversation with an agent.

Check out these resources to get more familiar with Rime:

<CardGroup cols={2}>
  <Card title="Models" icon="microchip" href="/api-reference/models">
    Compare Arcana (realistic) and Mistv2 (fast)
  </Card>
  <Card title="Voices" icon="waveform" href="/api-reference/voices">
    Browse all available voice options
  </Card>
  <Card title="Latency" icon="gauge-high" href="/api-reference/latency">
    Optimize for real-time performance
  </Card>
  <Card title="Arcana Streaming API" icon="bolt" href="/api-reference/arcana/streaming-mp3">
    Stream audio with our most realistic model
  </Card>
</CardGroup>
